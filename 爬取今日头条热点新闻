import requests
import json
import time
import math
import hashlib
from xlwt import Workbook
news_set=[]
def getas_cp():
    zz ={}
    now = round(time.time())
    e = hex(int(now)).upper()[2:]#转换为16进制字符串
    i = hashlib.md5(str(int(now))).hexdigest().upper()
    if len(e)!=8:
        zz = {'as': "479BB4B7254C150", 'cp': "7E0AC8874BB0985"}
        return zz
    n=i[:5]
    a=i[-5:]
    r = ""
    s = ""
    for i in range(5):
        s=s+n[i]+e[i]
    for j in range(5):
        r=r+e[j+3]+a[j]
    zz={'as': "A1" + s + e[-3:],'cp': e[0:3] + r + "E1"}
    return zz
def get_cookies():
    f=open(r'D:\cookie.txt','r')#打开所保存的cookies内容文件  
    cookies={}#初始化cookies字典变量  
    for line in f.read().split(';'):   #按照字符：进行划分读取  
        #其设置为1就会把字符串拆分成2份  
        name,value=line.strip().split('=',1)  
        cookies[name]=value  #为字典cookies添加内容  
    return cookies   
def get_pageinfo(url):
    global news_set
    cookies=get_cookies()
    headers={
    "Accept":"text/javascript, text/html, application/xml, text/xml, */*",
    "Accept-Encoding":"gzip, deflate",
    "Accept-Language":"zh-CN,zh;q=0.8",
    "Host":"www.toutiao.com",
    "Referer":"http://www.toutiao.com/ch/news_hot/",
    "User-Agent":"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36"
    }
    req=requests.get(url,headers=headers,cookies=cookies)
    wbdata=requests.get(url,headers=headers,cookies=cookies).text
    data=json.loads(wbdata)
    items=data['data']
    max_behot_time=data['next']['max_behot_time']
    result={'news':[],'max_behot_time':max_behot_time}
    for item in items:
        news = {'title': None,
                 'chinese_tag': None,
                'news_url':None,
                'media_url':None,
                'comments_count':None
                }
        if item['is_feed_ad']==False:
            if 'comments_count' in item: 
                comments_count=item['comments_count']  
            else:comments_count=0
            
            if 'title' in item:
                title=item['title']
            else:title=None
            if 'chinese_tag' in item:
                 chinese_tag=item['chinese_tag']
            else:chinese_tag=None
            if 'media_url' in item:
                 media_url='http://www.toutiao.com'+item['media_url']
            else:media_url=None
            if 'group_id' in item:
                news_url='http://www.toutiao.com/a'+item['group_id']
            else:news_url=None
            #print title,comments_count,news_url
            news['title']=title
            news['chinese_tag']=chinese_tag
            news['news_url']=news_url
            news['media_url']=media_url
            news['comments_count']=comments_count
        #result['news'].append(news)
        news_set.append(news)
    return max_behot_time
def get_url(timestamp):
    AS=getas_cp()['as']
    CP=getas_cp()['cp']
    url='http://www.toutiao.com/api/pc/feed/?category=news_hot&utm_source=toutiao&widen=1&max_behot_time='+str(timestamp)+'&max_behot_time_tmp='+str(timestamp)+'&tadrequire=true&as='+AS+'&cp='+CP
    return url
url=get_url(0)
first_timestamp=get_pageinfo(url)
def write_excel():
    #写入表头
    book = Workbook()
    sheet= book.add_sheet('toutiao')
    sheet.write(0, 0, 'title')
    sheet.write(0, 1, 'chinese_tag')
    sheet.write(0, 2, 'news_url')
    sheet.write(0, 3, 'media_url')
    sheet.write(0, 4, 'comments_count')
    #写入数据
    for i in range(len(news_set)):
        sheet.write(i+1, 0, news_set[i]['title'])
        sheet.write(i+1, 1, news_set[i]['chinese_tag'])
        sheet.write(i+1, 2, news_set[i]['news_url'])
        sheet.write(i+1, 3, news_set[i]['media_url'])
        sheet.write(i+1, 4, news_set[i]['comments_count']) 
    book.save('D:\\toutiao.xls')

for i in range(1):
    print('第%d次：' % i)
    _url=get_url(first_timestamp)
    get_pageinfo(_url)
    first_timestamp=get_pageinfo(_url)
#num = [a for a in news_set]     
write_excel()
